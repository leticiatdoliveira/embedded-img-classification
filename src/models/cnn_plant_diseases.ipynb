{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiatdoliveira/embedded-img-classification/blob/features-cnn/cnn_plant_diseases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FdA6yFUZDTA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3c7EA6xCYFH"
      },
      "source": [
        "# Install some packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjC5q9ZbybQq",
        "outputId": "55715ebe-7553-499c-8dcc-033f60621936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/242.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWMkIl4YCcbC"
      },
      "source": [
        "# Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJzPZ-FgZd73",
        "outputId": "711766e9-1903-4881-b663-631e00191495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "else:\n",
        "  print('Drive already mounted')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq9Ah4xXJ6Yx"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgk9vKOyJont"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow_model_optimization.python.core.keras.compat import keras\n",
        "\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zcUSOddmawQ"
      },
      "outputs": [],
      "source": [
        "# shutil.rmtree('/content/data/plantvillage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWeFXI92miwT"
      },
      "outputs": [],
      "source": [
        "# shutil.rmtree('/content/results/plant-village')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfp5M2ST-Xq9"
      },
      "source": [
        "Explore some runtime ressources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grRX8STP9TNs",
        "outputId": "1e44d83e-f6e4-4e81-88c5-bf9989754915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "List of GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(\"List of GPUs Available: \", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mdbDD9oJ-Qc"
      },
      "source": [
        "# Global variables setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOOJ-EoyT_jt"
      },
      "outputs": [],
      "source": [
        "PLANT_CULTURE = \"tomato\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIyz4g0_RDbF"
      },
      "outputs": [],
      "source": [
        "DOWNLOAD_DATA = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBCvmSMdXWLx"
      },
      "outputs": [],
      "source": [
        "DELETE_SOME_SUBFOLDERS = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fB9y31KenH"
      },
      "source": [
        "Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vENGuBPpKw0k"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'PlantVillage'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbqUMOoSmZtB",
        "outputId": "0f2c2d7f-009f-491e-ca65-5d4f39dcdbab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project dir: /content\n"
          ]
        }
      ],
      "source": [
        "project_dir = os.getcwd()\n",
        "print(f\"Project dir: {project_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ3Xa379mVBM",
        "outputId": "d3f00beb-fde7-44ad-bda4-ae74214d5d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive dir: /content/drive/MyDrive/IC_VANT/PlantVillage\n"
          ]
        }
      ],
      "source": [
        "drive_dir = project_dir +'/drive/MyDrive/IC_VANT/PlantVillage'\n",
        "if not os.path.exists(drive_dir):\n",
        "    os.makedirs(drive_dir)\n",
        "print(f\"Drive dir: {drive_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UivbRsl7JnqQ",
        "outputId": "27274d93-6fd4-4eae-e6ce-a365987db1e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data dir: /content/drive/MyDrive/IC_VANT/PlantVillage/data\n"
          ]
        }
      ],
      "source": [
        "data_dir: str = drive_dir + '/data'\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "print(f\"Data dir: {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvc0mBRQKsSb",
        "outputId": "5e488648-52c8-444e-a926-21ac620d8101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results dir: /content/drive/MyDrive/IC_VANT/PlantVillage/results\n"
          ]
        }
      ],
      "source": [
        "results_dir = drive_dir + '/results'\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "print(f\"Results dir: {results_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoLOLiu4KgwQ"
      },
      "source": [
        "Model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dibn7XgGKiuL"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-D01gGiKmFp"
      },
      "source": [
        "Image parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUGW4ZnhZCRz"
      },
      "outputs": [],
      "source": [
        "IMAGE_HEIGHT = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6rY88w2ZFe4"
      },
      "outputs": [],
      "source": [
        "IMAGE_WIDTH = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0r3yqwbKpCM"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B62GqwmVJjpA"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqwMyLvBJc3X"
      },
      "outputs": [],
      "source": [
        "def check_data_dir(silent_console: bool = True):\n",
        "    \"\"\"\n",
        "    check if the data_dir exists\n",
        "\n",
        "    :param:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if os.path.exists(data_dir):\n",
        "        print(\"Data_dir found !\") if not silent_console else None\n",
        "        return True\n",
        "    else:\n",
        "        print(\"The data_dir not found !\") if not silent_console else None\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztHH5QFsOiWz"
      },
      "source": [
        "## Dataset manip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIO2NT14K_fE"
      },
      "outputs": [],
      "source": [
        "def get_dataset_info(directory: str) -> int:\n",
        "    \"\"\"\n",
        "    get the number of images in the dataset\n",
        "\n",
        "    :param directory: str\n",
        "    :return: int\n",
        "    \"\"\"\n",
        "    dir_path = Path(directory)\n",
        "    image_count = len(list(dir_path.glob('*/*.jpg')))\n",
        "    image_count += len(list(dir_path.glob('*/*.JPG')))\n",
        "    return image_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuZelqFRX5A6"
      },
      "outputs": [],
      "source": [
        "def check_nb_of_data_in_dataset(dataset: tf.data.Dataset):\n",
        "    \"\"\"\n",
        "    check the number of data in the dataset\n",
        "\n",
        "    :param dataset: tf.data.Dataset\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    nb_of_batches = dataset.cardinality().numpy()\n",
        "    nb_of_data = nb_of_batches * BATCH_SIZE\n",
        "    print(f\"Nb of data: {nb_of_data} | Nb of batches: {nb_of_batches}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8_TO1brYSHf"
      },
      "outputs": [],
      "source": [
        "def check_nb_of_classes_in_dataset(dataset: tf.data.Dataset):\n",
        "    \"\"\"\n",
        "    check the number of classes in the dataset\n",
        "\n",
        "    :param dataset: tf.data.Dataset\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    class_names = dataset.class_names\n",
        "    print(f\"Nb of classes: {len(class_names)} | Class names: {class_names}\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4U1_GlALQrc"
      },
      "outputs": [],
      "source": [
        "def load_split_dataset(val_split: float, test_split: float, silent_console: bool = True):\n",
        "    \"\"\"\n",
        "    load and split the dataset\n",
        "\n",
        "    :return: tf.data.Dataset, tf.data.Dataset, tf.data.Dataset\n",
        "    \"\"\"\n",
        "    # get training dataset\n",
        "    eval_split = val_split + test_split\n",
        "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=eval_split,\n",
        "        subset=\"training\",\n",
        "        seed=123,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    # get data to eval (validation and test)\n",
        "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split=eval_split,\n",
        "        subset=\"validation\",\n",
        "        seed=123,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFl57VfsMOBV"
      },
      "outputs": [],
      "source": [
        "def get_dataset_classes(dataset: tf.data.Dataset, dataset_type: str, silent_console: bool = True):\n",
        "    \"\"\"\n",
        "    check the dataset classes\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    class_names = dataset.class_names\n",
        "    if not silent_console:\n",
        "        print(f\"Dataset: {dataset_type} | Nb of classes: {len(class_names)} | Class names: {class_names}\")\n",
        "    return class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXPMRRMxM_eY"
      },
      "outputs": [],
      "source": [
        "def check_batch_size(dataset: tf.data.Dataset, dataset_type: str):\n",
        "    \"\"\"\n",
        "    check the batch size of the dataset\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print(f\"\\n------ Checking batch size of the {dataset_type} dataset...\")\n",
        "    for image_batch, labels_batch in dataset:\n",
        "        print(f\"Image batch shape: {image_batch.shape}\")\n",
        "        print(f\"Label batch shape: {labels_batch.shape}\\n\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFGMF9n8NDxZ"
      },
      "outputs": [],
      "source": [
        "def display_img_sample_of_dataset(dataset: tf.data.Dataset, dataset_type: str):\n",
        "    \"\"\"\n",
        "    display a sample of images from the dataset\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    class_names = dataset.class_names\n",
        "\n",
        "    # Take one batch of images and create a subplot\n",
        "    for images, labels in dataset.take(1):\n",
        "        for i in range(9):\n",
        "            ax = plt.subplot(3, 3, i + 1)  # Create the subplot\n",
        "            ax.imshow(images[i].numpy().astype(\"uint8\"))  # Show the image\n",
        "\n",
        "            # Set the title on the subplot (not the entire plot)\n",
        "            ax.set_title(f\"{class_names[labels[i]]}\", fontsize=8)\n",
        "            ax.axis(\"off\")  # Remove the axis labels\n",
        "\n",
        "    # Adjust layout to prevent overlapping titles\n",
        "    plt.subplots_adjust(top=0.9, bottom=0.1, left=0.1, right=0.9, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # Add a title to the entire plot\n",
        "    plt.suptitle(f\"Sample of images from the {dataset_type} dataset\", fontsize=16)\n",
        "\n",
        "    # Save the plot\n",
        "    if not os.path.exists(results_dir):\n",
        "        os.makedirs(results_dir)\n",
        "    plt.savefig(results_dir + f\"sample_images_{dataset_type}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubHJYkoENWOv"
      },
      "outputs": [],
      "source": [
        "def set_prefetch(dataset: tf.data.Dataset):\n",
        "    \"\"\"\n",
        "    set the prefetch for the dataset\n",
        "\n",
        "    :param dataset: tf.data.Dataset\n",
        "    :return: tf.data.Dataset\n",
        "    \"\"\"\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    return dataset.shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5v1sehCNais"
      },
      "outputs": [],
      "source": [
        "def normalize_dataset(dataset: tf.data.Dataset, silent_console: bool = True):\n",
        "    \"\"\"\n",
        "    Normalize image data.\n",
        "    RGB values are in the [0, 255] range, so we need to scale them to the [0, 1] range.\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print(\"Normalizing dataset...\")\n",
        "    normalizer_layer = keras.layers.Rescaling(1. / 255)\n",
        "    normalized_ds = dataset.map(lambda x, y: (normalizer_layer(x), y))\n",
        "    image_batch, labels_batch = next(iter(normalized_ds))\n",
        "\n",
        "    # get the first image to check the pixel values\n",
        "    if not silent_console:\n",
        "        first_image = image_batch[0]\n",
        "        print(f\"First image pixel values -> Min: {np.min(first_image)} | Max: {np.max(first_image)} | \"\n",
        "              f\"Shape: {first_image.shape}\")\n",
        "    return normalized_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOf0N2o2NqSE"
      },
      "outputs": [],
      "source": [
        "def show_first_data_in_dataset(dataset: tf.data.Dataset, class_names: list):\n",
        "    \"\"\"\n",
        "    Show the first data in the dataset\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print(\"\\n---- Showing the first data in the dataset...\")\n",
        "    # get the first batch of data\n",
        "    for image, label in dataset.take(1):\n",
        "        # Show the first image and label\n",
        "        first_img = image[0]\n",
        "        first_label = label[0]\n",
        "        print(f\"First image shape: {first_img.shape} | First label: {first_label}\")\n",
        "        print(f\"First image pixel values -> Min: {np.min(first_img)} | Max: {np.max(first_img)}\")\n",
        "\n",
        "        # Display the first image\n",
        "        plt.figure()\n",
        "        plt.imshow(first_img)\n",
        "        plt.title(f\"First image example | Label: {first_label} | Class name: {class_names[first_label]}\")\n",
        "        plt.grid(False)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqgPPc_IN-k4"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIXLo8oERnSo"
      },
      "outputs": [],
      "source": [
        "def data_augmentation():\n",
        "    \"\"\"\n",
        "    Create a data augmentation layer\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "        keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        keras.layers.RandomRotation(0.2),\n",
        "    ])\n",
        "    return data_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VccThl__N6sM"
      },
      "outputs": [],
      "source": [
        "def create_model(class_names: list, img_height: int, img_width: int):\n",
        "    \"\"\"\n",
        "    Create a CNN model to classify image\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    num_classes = len(class_names)\n",
        "    image_shape = (img_height, img_width, 3)\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=image_shape),\n",
        "        #data_augmentation(),\n",
        "        keras.layers.Reshape((img_height, img_width, 3)),\n",
        "        keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkyhfd1hOAhQ"
      },
      "outputs": [],
      "source": [
        "def compile_mode(model: tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Compile the model\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91qFwsEMOHnr"
      },
      "outputs": [],
      "source": [
        "def show_model_fit(hist: tf.keras.callbacks.History, nb_epochs: int):\n",
        "    \"\"\"\n",
        "    Show the model fit\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    acc = hist.history['accuracy']\n",
        "    val_acc = hist.history['val_accuracy']\n",
        "\n",
        "    loss = hist.history['loss']\n",
        "    val_loss = hist.history['val_loss']\n",
        "\n",
        "    epochs_range = range(nb_epochs)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    # Save the plot\n",
        "    if not os.path.exists(results_dir):\n",
        "        os.makedirs(results_dir)\n",
        "    plt.savefig(results_dir + \"model_fit.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN7TR5lUOIjS"
      },
      "outputs": [],
      "source": [
        "def save_model(model: tf.keras.Model, model_name: str, file_format: str = \"keras\"):\n",
        "    \"\"\"\n",
        "    Save the model\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if not os.path.exists(results_dir):\n",
        "        raise ValueError(\"Results dir not found !\")\n",
        "    model_file = model_name + \".\" + file_format\n",
        "    model_path = results_dir + '/' + model_file\n",
        "    model.save(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SobR-_Q-sAF7"
      },
      "outputs": [],
      "source": [
        "def create_checkpoint_weights_callback(flag_quant : bool):\n",
        "    \"\"\"\n",
        "    Create a checkpoint callback to save trained weights per epoch done.\n",
        "\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if flag_quant:\n",
        "      checkpoint_dir = results_dir + \"/training_checkpoints_quant\"\n",
        "    else:\n",
        "      checkpoint_dir = results_dir + \"/training_checkpoints\"\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_prefix,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "    return checkpoint_callback, checkpoint_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBlGuIsusxBG"
      },
      "outputs": [],
      "source": [
        "def weights_files_key(filename):\n",
        "    \"\"\"\n",
        "    Get the epoch number of each trained weight saved.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename: str\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    nb of the epoch\n",
        "    \"\"\"\n",
        "    base_name = filename.split('.')[0]\n",
        "    epoch_number = base_name.split('_')[1]\n",
        "    print(f\"Epoch number: {epoch_number} | Base name: {base_name}\")\n",
        "    return int(epoch_number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mq-vi-VJZVB"
      },
      "source": [
        "# Main code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNbk6uaRQvvE"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2hEurlcoPw1I",
        "outputId": "794f3d6a-0adc-4e89-a6c3-825f5ec05888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data already downloaded !\n"
          ]
        }
      ],
      "source": [
        "if DOWNLOAD_DATA:\n",
        "  import kagglehub\n",
        "\n",
        "  # download\n",
        "  !kaggle datasets download -d emmarex/plantdisease -p /content/data --unzip\n",
        "\n",
        "  #rename data folder\n",
        "  !mv content/data/PlantVillage/ /content/drive/MyDrive/IC_VANT/PlantVillage/data\n",
        "\n",
        "  # delete dir where we have downloaded data\n",
        "  shutil.rmtree('/content/data')\n",
        "else:\n",
        "  print(\"Data already downloaded !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5EbesS_VNvW"
      },
      "source": [
        "Check subfolders in data_dir, delete all subdirectories with a culture different of our set culture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KsYAcvP5UOzI"
      },
      "outputs": [],
      "source": [
        "if DELETE_SOME_SUBFOLDERS:\n",
        "\n",
        "  def delete_subfolders(data_dir, target_culture):\n",
        "    for subdir in os.listdir(data_dir):\n",
        "        subdir_path = os.path.join(data_dir, subdir)\n",
        "        print(f\"Checking subdirectory: {subdir_path}\")\n",
        "        if os.path.isdir(subdir_path) and PLANT_CULTURE in subdir.lower():\n",
        "            print(f\"Keeping subdirectory: {subdir_path}\")\n",
        "        else:\n",
        "            # move subdir to plant-village-others\n",
        "            path = data_dir + '-others'\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "            print(f\"Moving subdirectory: {subdir_path} to {path}\")\n",
        "            shutil.move(subdir_path, os.path.join(path, 'plant-village-others'))\n",
        "        print(\"\\n\")\n",
        "\n",
        "  delete_subfolders(data_dir, PLANT_CULTURE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRdboGRFOviT"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6_Mb2E1JDR2",
        "outputId": "abc7d1c6-2e19-451b-b640-1e849b2033f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# PLANTVILLAGE dataset contains 16010 images\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not check_data_dir():\n",
        "  raise ValueError(\"Data dir not found !\")\n",
        "nb_img_data = get_dataset_info(data_dir)\n",
        "print(f\"# {dataset_name.upper()} dataset contains {nb_img_data} images\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0jh8ZKALIX6",
        "outputId": "e24cb9da-6b6b-4e68-f7a0-1113aa74cd08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 16011 files belonging to 10 classes.\n",
            "Using 9607 files for training.\n",
            "Found 16011 files belonging to 10 classes.\n",
            "Using 6404 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset = load_split_dataset(0.2, 0.2, silent_console=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBrpnHZEMF4d"
      },
      "source": [
        "### Check dataset classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NPqUMTuMFc6",
        "outputId": "5bae9df0-6be1-4400-b048-7bb752b6c9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nb of class: 10 | Classes: ['Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_classes = get_dataset_classes(train_dataset, \"train\")\n",
        "val_classes = get_dataset_classes(val_dataset, \"validation\")\n",
        "if train_classes != val_classes:\n",
        "    raise ValueError(\"The classes in the train and validation datasets are different\")\n",
        "else:\n",
        "    print(f\"Nb of class: {len(train_classes)} | Classes: {train_classes}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wborzIe6M3E1"
      },
      "source": [
        "### Display sample of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adVtZhg6NGKR"
      },
      "source": [
        "Train img sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g_f9hUUM2n5",
        "outputId": "3720dec8-8b6e-4813-d1b5-97ce6704856b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------ Checking batch size of the train dataset...\n",
            "Image batch shape: (4, 256, 256, 3)\n",
            "Label batch shape: (4,)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "check_batch_size(train_dataset, \"train\")\n",
        "# display_img_sample_of_dataset(train_dataset, \"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISlKhq22NI7Y"
      },
      "source": [
        "Validation img sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGwnfpNmNNjv",
        "outputId": "f7c47f50-03c7-4510-ae7a-3131150f3d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------ Checking batch size of the validation dataset...\n",
            "Image batch shape: (4, 256, 256, 3)\n",
            "Label batch shape: (4,)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "check_batch_size(val_dataset, \"validation\")\n",
        "# display_img_sample_of_dataset(val_dataset, \"validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCHnGdHKNPSi"
      },
      "source": [
        "## Data pre-processing and cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oQN6GBOPC9t"
      },
      "source": [
        "### Prefetch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl3xI5JKNSJv",
        "outputId": "88f23315-ea6b-49ac-9024-c2932ff4866c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---- Setting prefetch for the dataset...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n---- Setting prefetch for the dataset...\")\n",
        "train_dataset = set_prefetch(train_dataset)\n",
        "val_dataset = set_prefetch(val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utGSRnffNeYP"
      },
      "source": [
        "### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "G011XsPvNYDk",
        "outputId": "c124788c-5693-4be5-e140-f7b8538621ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---- Normalizing dataset...\n",
            "Normalizing dataset...\n",
            "Normalizing dataset...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n---- Normalizing dataset...\")\n",
        "train_dataset_normalized = normalize_dataset(train_dataset)\n",
        "val_dataset_normalized = normalize_dataset(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVtV6fE7Nrib"
      },
      "outputs": [],
      "source": [
        "# show_first_data_in_dataset(train_dataset_normalized, train_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZpGDF0ENuB4"
      },
      "source": [
        "## Create and fit a CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgOxcf0nUwGi"
      },
      "source": [
        "### Visualize some augmented images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnCi3lwqPMha"
      },
      "source": [
        "### Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sv54jISHvGW9"
      },
      "outputs": [],
      "source": [
        "print(\"\\n---- Building the model...\")\n",
        "model = create_model(train_classes, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "model = compile_mode(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RaLBwUSxvJQH"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj7S6qbRq2G2"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oon2wKUzq1v-"
      },
      "outputs": [],
      "source": [
        "start_ep = -1\n",
        "fit_model = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNfLJSnWrwsZ"
      },
      "source": [
        "Create callbacks to save fit by epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpekkchgrwaE"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback, checkpoint_dir = create_checkpoint_weights_callback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_RYcvA5yhqA"
      },
      "outputs": [],
      "source": [
        "print(f\"Checkpoint_dir: {checkpoint_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTzLuctoscT3"
      },
      "source": [
        "Check entire model fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDLSqIPmvfzH"
      },
      "outputs": [],
      "source": [
        "if start_ep == -1:\n",
        "  # check the entire model\n",
        "  if os.path.exists(results_dir + \"cnn_first_model.keras\"):\n",
        "    print(\"\\n---- An entire model is already saved !\")\n",
        "    print(\"\\n---- Loading the model...\")\n",
        "    model = keras.models.load_model(results_dir + '/' + f\"cnn_model_ep={EPOCHS}.keras\")\n",
        "    fit_model = False\n",
        "  else:\n",
        "    start_ep = 0\n",
        "    print(\"\\n---- No entire model saved !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt9c12xJxEyL"
      },
      "source": [
        "Check checkpoints of epochs fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzVKCkUzvZKF"
      },
      "outputs": [],
      "source": [
        "if start_ep == 0:\n",
        "  print(f\"\\n---- Checking ckpt results\")\n",
        "\n",
        "  if os.path.exists(checkpoint_dir):\n",
        "    files = os.listdir(checkpoint_dir)\n",
        "    if len(files) > 0:\n",
        "      print(f\"\\n We found some ckpt model files !\")\n",
        "\n",
        "      highest_epoch_file = max(files, key=weights_files_key)\n",
        "      highest_epoch = weights_files_key(highest_epoch_file)\n",
        "      print(f\"Highest epoch: {highest_epoch}\")\n",
        "\n",
        "      # get the last epoch fitting\n",
        "      if highest_epoch < EPOCHS:\n",
        "        start_ep = highest_epoch\n",
        "        path_to_load_model = os.path.join(checkpoint_dir, \"ckpt_{}.weights.h5\".format(start_ep))\n",
        "        print(\"\\n---- Loading weights of: {}\".format(path_to_load_model))\n",
        "        model.load_weights(path_to_load_model)\n",
        "        fit_model = True\n",
        "      else:\n",
        "        print(\"more or equal weights saved than EPOCHS\")\n",
        "        fit_model = False\n",
        "        start_ep = -1\n",
        "        # load checkpoint fitting\n",
        "        path_to_load_model = os.path.join(checkpoint_dir, \"ckpt_{}.weights.h5\".format(EPOCHS))\n",
        "        print(\"\\n---- Loading weights of: {}\".format(path_to_load_model))\n",
        "        model.load_weights(path_to_load_model)\n",
        "        # save as complete model\n",
        "        print(\"\\n---- Saving as an entire model...\")\n",
        "        save_model(model, f\"cnn_model_ep={EPOCHS}\")\n",
        "        print(\"\\n---- Complete model saved !\")\n",
        "    else:\n",
        "      print(f\"\\n No ckpt model files found !\")\n",
        "      fit_model = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4DkeVQYxiiS"
      },
      "source": [
        "Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlKSiLPpbEPd"
      },
      "outputs": [],
      "source": [
        "print(start_ep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejQRHb1xxPq-"
      },
      "outputs": [],
      "source": [
        "if fit_model:\n",
        "  print(\"\\n---- Fitting the model...\")\n",
        "  print(f\"Start epoch: {start_ep}\")\n",
        "  print(f\"End epoch: {EPOCHS}\\n\")\n",
        "\n",
        "  # fit using GPU\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    hist = model.fit(train_dataset_normalized,\n",
        "                    validation_data=val_dataset_normalized,\n",
        "                    epochs=EPOCHS,\n",
        "                    initial_epoch=start_ep,\n",
        "                    callbacks=[checkpoint_callback]\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ3leWU7CAWa"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.name, layer.output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLIffh2abMKt"
      },
      "outputs": [],
      "source": [
        "if fit_model:\n",
        "  show_model_fit(hist, EPOCHS)\n",
        "  save_model(model, f\"cnn_model_ep={EPOCHS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d_HI4ITOQOk"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8JrJ1BUOXXW"
      },
      "outputs": [],
      "source": [
        "print(\"\\n---- Evaluating the model...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj7lNNIQOSwa"
      },
      "outputs": [],
      "source": [
        "print(\"### Val dataset evaluation:\")\n",
        "val_score = model.evaluate(val_dataset_normalized)\n",
        "print(f\"Val accuracy: {val_score[1]*100.00:.2f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzZFZC92ObpB"
      },
      "outputs": [],
      "source": [
        "print(\"### Train dataset evaluation:\")\n",
        "train_score = model.evaluate(train_dataset_normalized)\n",
        "print(f\"Train accuracy: {train_score[1]*100.00:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik0xXfWazgJs"
      },
      "source": [
        "## Create a Quantization Aware Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnFDmvCZ0u-2"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0BEy37nuv_R"
      },
      "source": [
        "### Quantize layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYUn-TZE02vd"
      },
      "outputs": [],
      "source": [
        "base_model = keras.models.clone_model(model)\n",
        "base_model.set_weights(model.get_weights())\n",
        "base_model = compile_mode(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LelYOBdl09nb"
      },
      "source": [
        "Test model copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRLrEti_1Bq6"
      },
      "outputs": [],
      "source": [
        "print(\"### Train dataset evaluation (COPY MODEL):\")\n",
        "train_score = base_model.evaluate(train_dataset_normalized)\n",
        "print(f\"Train accuracy: {train_score[1]*100.00:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2n7JyvCt549"
      },
      "source": [
        "Check model type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4PAkq0a3pVj"
      },
      "outputs": [],
      "source": [
        "print(type(base_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JNzRZi3t2L9"
      },
      "source": [
        "Check tensorflow and keras version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gU-SsoE4X0t"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-nJOy90nDP"
      },
      "source": [
        "Create quantize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0xEmZN6uljm"
      },
      "outputs": [],
      "source": [
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsNEwiQuunZC"
      },
      "source": [
        "Apply quantization-aware in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTXEmYwwzzGc"
      },
      "outputs": [],
      "source": [
        "quant_aware_model = quantize_model(base_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4hoKwPup50"
      },
      "source": [
        "### Compile and fit the quantization model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUIYOymXu6ad"
      },
      "source": [
        "Compile the quantization model with the same compilation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EgGsrROvflf"
      },
      "outputs": [],
      "source": [
        "quant_aware_model = compile_mode(quant_aware_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "konXxeGyvdn-"
      },
      "outputs": [],
      "source": [
        "quant_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM0lk0OuvBC-"
      },
      "source": [
        "Fit the quantization model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0SBuwaJv1W5"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback_quant, checkpoint_dir_quant = create_checkpoint_weights_callback(flag_quant=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaOwXVsrwPMl"
      },
      "outputs": [],
      "source": [
        "print(f\"Checkpoint_dir_quant: {checkpoint_dir_quant}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlaXfmBuu4HU"
      },
      "outputs": [],
      "source": [
        "quant_aware_model.fit(train_dataset_normalized,\n",
        "                      batch_size=32,\n",
        "                      validation_data=val_dataset_normalized,\n",
        "                      epochs=EPOCHS,\n",
        "                      callbacks=[checkpoint_callback_quant]\n",
        "                      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8hmifwlvGo-"
      },
      "source": [
        "### Save q-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVwpBP3AvJFv"
      },
      "outputs": [],
      "source": [
        "save_model(quant_aware_model, f\"cnn_quant_aware_model_ep={EPOCHS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6cmk5J_vUlY"
      },
      "source": [
        "### Evaluate q-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7b9mote08eZ"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] Calculating Quant Aware model accuracy\")\n",
        "scores_val = quant_aware_model.evaluate(val_dataset_normalized)\n",
        "print(f\"Val Accuracy: {scores_val[1]*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gydynCZiIPik"
      },
      "outputs": [],
      "source": [
        "scores_train = quant_aware_model.evaluate(train_dataset_normalized)\n",
        "print(f\"Train Accuracy: {scores_train[1]*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZB1tzYs1MYO"
      },
      "source": [
        "## TF to TFlite\n",
        "\n",
        "Convert model to tensorflowlite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fwmSZr150cS"
      },
      "outputs": [],
      "source": [
        "print(quant_aware_model.input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GwYuUDF4fW6"
      },
      "outputs": [],
      "source": [
        "input_shape = (1, 256, 256, 3)\n",
        "def representative_data_gen():\n",
        "  for _ in range(100):  # Adjust the number of samples as needed\n",
        "    dummy_input = np.random.rand(*input_shape).astype(np.float32)  # Generate dummy input\n",
        "    yield [dummy_input]  # Yield as a list containing a single input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GxFnhZj1Sh5"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmZDjGMZ5RiS"
      },
      "outputs": [],
      "source": [
        "quantized_tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSgFOKY91tuh"
      },
      "source": [
        "Save TFlite model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04VkUE3G6Y_c"
      },
      "outputs": [],
      "source": [
        "file_to_save_TFlite = results_dir + '/' + f\"tflite_model_ep={EPOCHS}.tflite\"\n",
        "print(file_to_save_TFlite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KkiLFic1v3P"
      },
      "outputs": [],
      "source": [
        "with open(file_to_save_TFlite,\"wb\") as f:\n",
        "    f.write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMyvanlGGs9a"
      },
      "source": [
        "Test TF model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iEFudCPGuzL"
      },
      "outputs": [],
      "source": [
        "def evaluate_tflite_model (dataset, interpreter):\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "    prediction_digits = []\n",
        "    test_labels = []\n",
        "    for image, label in dataset.unbatch().take(dataset.unbatch().cardinality()):\n",
        "\n",
        "        test_image = np.expand_dims(image, axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        interpreter.invoke()\n",
        "\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        test_labels.append(label)\n",
        "\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V238p5_lGxbp"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = file_to_save_TFlite)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_IZsvjWG1Vn"
      },
      "outputs": [],
      "source": [
        "test_accuracy = evaluate_tflite_model(val_dataset_normalized, interpreter)\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "B62GqwmVJjpA",
        "BNbk6uaRQvvE",
        "CRdboGRFOviT",
        "4oQN6GBOPC9t",
        "utGSRnffNeYP",
        "wnCi3lwqPMha"
      ],
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1yvprMnCE-IyEE176AKbglj7FO6TVsWV4",
      "authorship_tag": "ABX9TyMVY0DQf/gO00SO5pobh4Pm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}